{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Construction (Algorithm Steps 1-7):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import helpers\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# import Dijkstra's shortest path algorithm\n",
    "from scipy.sparse import csgraph, csr_matrix\n",
    "\n",
    "# import graph building methods\n",
    "from sklearn.neighbors import kneighbors_graph, radius_neighbors_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_random_subset(data, frac, index):\n",
    "    \"\"\"\n",
    "    Choose a subset of data for computational efficiency\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "    frac: float 0 < number =< 1\n",
    "        fraction of data for which we compute the graph; if frac = 1, and data set large, then compute long\n",
    "    index: int\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "    \"\"\"\n",
    "    number_samples = np.int(np.rint(frac * data.values.shape[0]))\n",
    "    list_to_choose = (\n",
    "        np.arange(0, index).tolist()\n",
    "        + np.arange(index + 1, data.values.shape[0]).tolist()\n",
    "    )\n",
    "    chosen_indeces = np.random.choice(\n",
    "        list_to_choose,\n",
    "        replace=False,\n",
    "        size=number_samples,\n",
    "    )\n",
    "    chosen_indeces = [\n",
    "        index\n",
    "    ] + chosen_indeces.tolist()  # make sure sample under consideration included\n",
    "    data = data.iloc[chosen_indeces]\n",
    "    data = data.sort_index()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_constraints(data, i, keys_immutable, epsilon=0.5):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: pd.DataFrame\n",
    "    i : int\n",
    "        Position of immutable key\n",
    "    keys_immutable: list[str]\n",
    "        Immutable feature\n",
    "    epsilon: int\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray, np.ndarray\n",
    "    \"\"\"\n",
    "    immutable_constraint_matrix = np.outer(\n",
    "        data[keys_immutable[i]].values + epsilon,\n",
    "        data[keys_immutable[i]].values + epsilon,\n",
    "    )\n",
    "    immutable_constraint_matrix1 = immutable_constraint_matrix / ((1 + epsilon) ** 2)\n",
    "    immutable_constraint_matrix1 = ((immutable_constraint_matrix1 == 1) * 1).astype(\n",
    "        float\n",
    "    )\n",
    "    immutable_constraint_matrix2 = immutable_constraint_matrix / (epsilon**2)\n",
    "    immutable_constraint_matrix2 = ((immutable_constraint_matrix2 == 1) * 1).astype(\n",
    "        float\n",
    "    )\n",
    "    return immutable_constraint_matrix1, immutable_constraint_matrix2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(\n",
    "    data, immutable_constraint_matrix1, immutable_constraint_matrix2, is_knn, n\n",
    "):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: pd.DataFrame\n",
    "    immutable_constraint_matrix1: np.ndarray #I don't know what is this\n",
    "    immutable_constraint_matrix2: np.ndarray #I don't know what is this either\n",
    "    is_knn: bool\n",
    "    n: int\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    CSR matrix\n",
    "    \"\"\"\n",
    "    if is_knn:\n",
    "        graph = kneighbors_graph(data.values, n_neighbors=n, n_jobs=-1)\n",
    "    else:\n",
    "        graph = radius_neighbors_graph(data.values, radius=n, n_jobs=-1)\n",
    "    adjacency_matrix = graph.toarray()\n",
    "    adjacency_matrix = np.multiply(\n",
    "        adjacency_matrix,\n",
    "        immutable_constraint_matrix1,\n",
    "        immutable_constraint_matrix2,\n",
    "    )  # element wise multiplication\n",
    "    graph = csr_matrix(adjacency_matrix)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'your_dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Load your dataset\u001b[39;00m\n\u001b[0;32m      8\u001b[0m dataset_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myour_dataset.csv\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace with the actual path to your dataset\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mworkclass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfnlwgt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meducation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meducation-num\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmarital-status\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                                       \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moccupation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelationship\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrace\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapital-gain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapital-loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                                       \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhours-per-week\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnative-country\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mincome\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Choose the position of the immutable key (i) and specify the keys_immutable list\u001b[39;00m\n\u001b[0;32m     14\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Replace with the desired position\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\env_recourse\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\env_recourse\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\env_recourse\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\env_recourse\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\env_recourse\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\env_recourse\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\env_recourse\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'your_dataset.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import kneighbors_graph, radius_neighbors_graph\n",
    "\n",
    "dataset_path = 'adult.csv'\n",
    "# Load your dataset\n",
    "data = pd.read_csv(dataset_path, names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n",
    "                                       'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss',\n",
    "                                       'hours-per-week', 'native-country', 'income'])\n",
    "\n",
    "# Choose the position of the immutable key (i) and specify the keys_immutable list\n",
    "i = 0  # Replace with the desired position\n",
    "keys_immutable = ['age', 'education-num', 'capital-gain']  # Replace with your selected immutable feature names\n",
    "\n",
    "# Choose a random subset of the dataset\n",
    "frac = 0.5  # Fraction of data to choose\n",
    "index_to_exclude = 0  # Index to exclude from random selection (assuming this is your immutable key index)\n",
    "data_subset = choose_random_subset(data, frac, index_to_exclude)\n",
    "\n",
    "# Build immutable constraint matrices using build_constraints function\n",
    "immutable_constraint_matrix1, immutable_constraint_matrix2 = build_constraints(data_subset, i, keys_immutable)\n",
    "\n",
    "# Call the build_graph function with the loaded dataset and constraint matrices\n",
    "is_knn = True  # Set to True for k-nearest neighbors graph, False for radius graph\n",
    "n_neighbors_or_radius = 5  # Set the number of neighbors or radius based on your requirements\n",
    "\n",
    "graph = build_graph(data_subset[integer_columns], immutable_constraint_matrix1, immutable_constraint_matrix2, is_knn, n_neighbors_or_radius)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_counterfactuals(\n",
    "    candidates,\n",
    "    data,\n",
    "    immutable_constraint_matrix1,\n",
    "    immutable_constraint_matrix2,\n",
    "    index,\n",
    "    n,\n",
    "    y_positive_indeces,\n",
    "    is_knn,\n",
    "):\n",
    "    \"\"\"\n",
    "    Steps 1 to 3 of the FACE algorithm\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    candidate_counterfactuals_star: list\n",
    "    data: pd.DataFrame\n",
    "    immutable_constraint_matrix1: np.ndarray\n",
    "    immutable_constraint_matrix2: np.ndarray\n",
    "    index: int\n",
    "    n: int\n",
    "    y_positive_indeces: int\n",
    "    is_knn: bool\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "    \"\"\"\n",
    "    candidate_counterfactuals_star = copy.deepcopy(candidates)\n",
    "    # STEP 1 -- BUILD NETWORK GRAPH\n",
    "    graph = build_graph(\n",
    "        data, immutable_constraint_matrix1, immutable_constraint_matrix2, is_knn, n\n",
    "    )\n",
    "    # # STEP 2 -- APPLY SHORTEST PATH ALGORITHM  ## indeces=index (corresponds to x^F)\n",
    "    # distances, min_distance = shortest_path(graph, index)\n",
    "    # # STEP 3 -- FIND COUNTERFACTUALS\n",
    "    # # minimum distance candidate counterfactuals\n",
    "    # candidate_min_distances = [\n",
    "    #     min_distance,\n",
    "    #     min_distance + 1,\n",
    "    #     min_distance + 2,\n",
    "    #     min_distance + 3,\n",
    "    # ]\n",
    "    # min_distance_indeces = np.array([0])\n",
    "    # for min_dist in candidate_min_distances:\n",
    "    #     min_distance_indeces = np.c_[\n",
    "    #         min_distance_indeces, np.array(np.where(distances == min_dist))\n",
    "    #     ]\n",
    "    # min_distance_indeces = np.delete(min_distance_indeces, 0)\n",
    "    # indeces_counterfactuals = np.intersect1d(\n",
    "    #     np.array(y_positive_indeces), np.array(min_distance_indeces)\n",
    "    # )\n",
    "    # for i in range(indeces_counterfactuals.shape[0]):\n",
    "    #     candidate_counterfactuals_star.append(data.values[indeces_counterfactuals[i]])\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Candidate Target Generation (Algorithm Steps 8-11):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_search(\n",
    "    data,\n",
    "    index,\n",
    "    keys_immutable,\n",
    "    model,\n",
    "    n_neighbors=50,\n",
    "    p_norm=2,\n",
    "    mode=\"knn\",\n",
    "    frac=0.4,\n",
    "    radius=0.25,\n",
    "):\n",
    "    # This one implements the FACE method from\n",
    "    # Rafael Poyiadzi et al (2020), \"FACE: Feasible and Actionable Counterfactual Explanations\",\n",
    "    # Conference on AI, Ethics & Accountability (AIES, 2020)\n",
    "    \"\"\"\n",
    "    :param data: df\n",
    "    :param n_neighbors: int > 0; number of neighbors when constructing knn graph\n",
    "    :param step: float > 0; step_size for growing spheres\n",
    "    :param mode: str; either 'knn' or 'epsilon'\n",
    "    :param model: classification model (either tf keras, pytorch or sklearn)\n",
    "    :param p_norm: float=>1; denotes the norm (classical: 1 or 2)\n",
    "    :param frac: float 0 < number =< 1; fraction of data for which we compute the graph; if frac = 1, and data set large, then compute long\n",
    "    :param keys_immutable: list; list of input names that may not be searched over\n",
    "    :param radius: float > 0; parameter for epsilon density graph\n",
    "    :return: candidate_counterfactual_star: np array (min. cost counterfactual explanation)\n",
    "    \"\"\"\n",
    "    # Choose a subset of data for computational efficiency\n",
    "    data = choose_random_subset(data, frac, index)\n",
    "\n",
    "    # ADD CONSTRAINTS by immutable inputs into adjacency matrix\n",
    "    # if element in adjacency matrix 0, then it cannot be reached\n",
    "    # this ensures that paths only take same sex / same race / ... etc. routes\n",
    "    for i in range(len(keys_immutable)):\n",
    "        immutable_constraint_matrix1, immutable_constraint_matrix2 = build_constraints(\n",
    "            data, i, keys_immutable\n",
    "        )\n",
    "\n",
    "    # POSITIVE PREDICTIONS\n",
    "    y_predicted = model.predict_proba(data.values)\n",
    "    y_predicted = np.argmax(y_predicted, axis=1)\n",
    "    y_positive_indeces = np.where(y_predicted == 1)\n",
    "\n",
    "    if mode == \"knn\":\n",
    "        boundary = 3  # chosen in ad-hoc fashion\n",
    "        median = n_neighbors\n",
    "        is_knn = True\n",
    "\n",
    "    elif mode == \"epsilon\":\n",
    "        boundary = 0.10  # chosen in ad-hoc fashion\n",
    "        median = radius\n",
    "        is_knn = False\n",
    "    else:\n",
    "        raise ValueError(\"Only possible values for mode are knn and epsilon\")\n",
    "\n",
    "    neighbors_list = [\n",
    "        median - boundary,\n",
    "        median,\n",
    "        median + boundary,\n",
    "    ]\n",
    "\n",
    "    # obtain candidate targets (CT); two conditions need to be met:\n",
    "    # (1) CT needs to be predicted positively & (2) CT needs to have certain \"density\"\n",
    "    # for knn I interpret 'certain density' as sufficient number of neighbours\n",
    "    candidate_counterfactuals = []\n",
    "    for n in neighbors_list:\n",
    "        neighbor_candidates = find_counterfactuals(\n",
    "            candidate_counterfactuals,\n",
    "            data,\n",
    "            immutable_constraint_matrix1,\n",
    "            immutable_constraint_matrix2,\n",
    "            index,\n",
    "            n,\n",
    "            y_positive_indeces,\n",
    "            is_knn=is_knn,\n",
    "        )\n",
    "        candidate_counterfactuals += neighbor_candidates\n",
    "\n",
    "    candidate_counterfactual_star = np.array(candidate_counterfactuals)\n",
    "\n",
    "    # STEP 4 -- COMPUTE DISTANCES between x^F and candidate x^CF; else return NaN\n",
    "    if candidate_counterfactual_star.size == 0:\n",
    "        candidate_counterfactual_star = np.empty(\n",
    "            data.values.shape[1],\n",
    "        )\n",
    "        candidate_counterfactual_star[:] = np.nan\n",
    "\n",
    "        return candidate_counterfactual_star\n",
    "\n",
    "    if p_norm == 1:\n",
    "        c_dist = np.abs((data.values[index] - candidate_counterfactual_star)).sum(\n",
    "            axis=1\n",
    "        )\n",
    "    elif p_norm == 2:\n",
    "        c_dist = np.square((data.values[index] - candidate_counterfactuals)).sum(axis=1)\n",
    "    else:\n",
    "        raise ValueError(\"Distance not defined yet. Choose p_norm to be 1 or 2\")\n",
    "\n",
    "    min_index = np.argmin(c_dist)\n",
    "    candidate_counterfactual_star = candidate_counterfactual_star[min_index]\n",
    "\n",
    "    return candidate_counterfactual_star\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CARLA/carla/recourse_methods/processing/counterfactuals.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from carla.models.api import MLModel\n",
    "\n",
    "def check_counterfactuals(\n",
    "    mlmodel: MLModel,\n",
    "    counterfactuals: Union[List, pd.DataFrame],\n",
    "    factuals_index: pd.Index,\n",
    "    negative_label: int = 0,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Takes the generated list of counterfactuals from recourse methods and checks if these samples are able\n",
    "    to flip the label from 0 to 1. Every counterfactual which still has a negative label, will be replaced with an\n",
    "    empty row.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mlmodel:\n",
    "        Black-box-model we want to discover.\n",
    "    counterfactuals:\n",
    "        List or DataFrame of generated samples from recourse method.\n",
    "    factuals_index:\n",
    "        Index of the original factuals DataFrame.\n",
    "    negative_label:\n",
    "        Defines the negative label.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(counterfactuals, list):\n",
    "        df_cfs = pd.DataFrame(\n",
    "            np.array(counterfactuals),\n",
    "            columns=mlmodel.feature_input_order,\n",
    "            index=factuals_index.copy(),\n",
    "        )\n",
    "    else:\n",
    "        df_cfs = counterfactuals.copy()\n",
    "\n",
    "    df_cfs[mlmodel.data.target] = np.argmax(mlmodel.predict_proba(df_cfs), axis=1)\n",
    "    # Change all wrong counterfactuals to nan\n",
    "    df_cfs.loc[df_cfs[mlmodel.data.target] == negative_label, :] = np.nan\n",
    "\n",
    "    return df_cfs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mR_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
